{
  "hash": "0aef847a9f83b511562b0e405df1e416",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Advanced Machine Learning with Python (Session 2 - Part 2)\nauthor: Fernando Cervantes (fernando.cervantes@jax.org)\nformat: \n  revealjs:\n    code-fold: false\n    progress: true\n    controls: true\n    output-file: \"Adv_ML_Python_presentation_2_2\"\n    fontsize: 20pt\n\nexecute:\n  error: false\n  echo: true\n  cache: true\n  freeze: true\n  keep-ipynb: true\n\njupyter: adv-ml\n---\n\n\n``` {.python}\n\n```\n\n# Tissue classification with the MoNuSAC dataset\n\n## Tissue classification with the MoNuSAC dataset\n\n* R. Verma, et al. \"MoNuSAC2020: A Multi-organ Nuclei Segmentation and Classification Challenge.\" IEEE Transactions on Medical Imaging (2021)\n\n![](../imgs/Tissue_classification.png)\n\n\n## Data preparation\n\n- [ ] Download the MoNuSAC dataset from https://monusac-2020.grand-challenge.org/Data/\n\n\n\n\n\n::: {.callout-note}\nMore information about the type of tissue of each image can be found [here](https://drive.google.com/file/d/1kdOl3s6uQBRv0nToSIf1dPuceZunzL4N/view).\n:::\n\n---\n\n## Tissue classification with the MoNuSAC dataset {.scrollable}\n\n- [ ] Explore the dataset\n\n::: {#e774ae96 .cell execution_count=4}\n``` {.python .cell-code}\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\nimg = imread(train_images_fns[0])\nplt.imshow(img)\nplt.title(tissue_classes[train_labels[0]])\nplt.show()\n\nimg = imread(test_images_fns[0])\nplt.imshow(img)\nplt.title(tissue_classes[test_labels[0]])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](DL_image_analysis_2_2_files/figure-revealjs/cell-4-output-1.png){width=481 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DL_image_analysis_2_2_files/figure-revealjs/cell-4-output-2.png){width=498 height=431}\n:::\n:::\n\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Define the pre-processing pipeline using the transforms from the pre-trained InceptionV3 model\n\n::: {#6a97f4b0 .cell execution_count=5}\n``` {.python .cell-code}\nimport torchvision\nfrom torchvision.transforms.v2 import Compose, ToTensor\n\ninception_weights = torchvision.models.inception.Inception_V3_Weights.IMAGENET1K_V1\n\npipeline = Compose([\n  ToTensor(),\n  inception_weights.transforms()\n])\n\npipeline\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Create a dataset class to load the images from disk\n\n::: {#bce2fcdf .cell execution_count=6}\n``` {.python .cell-code}\nfrom torch.utils.data import Dataset\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, image_filenames, image_labels, transform):\n        self.image_filenames = image_filenames\n        self.image_labels = image_labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_labels)\n\n    def __getitem__(self, idx):\n        image = imread(self.image_filenames[idx])\n        image = self.transform(image)\n\n        label = self.image_labels[idx]\n\n        return image, label\n```\n:::\n\n\n- [ ] Create the training and test sets using the `CustomImageDataset` class.\n\n::: {#935f307d .cell execution_count=7}\n``` {.python .cell-code}\ntrain_ds = CustomImageDataset(train_images_fns, train_labels, pipeline)\ntest_ds = CustomImageDataset(test_images_fns, test_labels, pipeline)\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Split the training set into train and validation subsets\n\n::: {#375a1c8f .cell execution_count=8}\n``` {.python .cell-code}\nfrom torch.utils.data import random_split\n\ntrain_ds, val_ds = random_split(train_ds, [0.8, 0.2])\n\nprint(f\"Training images={len(train_ds)}\")\nprint(f\"Validation images={len(val_ds)}\")\nprint(f\"Test images={len(test_ds)}\")\n```\n:::\n\n\n- [ ] Use a `DataLoader` to serve image batches from the datasets.\n\n::: {#ca661aa2 .cell execution_count=9}\n``` {.python .cell-code}\nfrom torch.utils.data import DataLoader\n\ntrain_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=128)\ntest_dl = DataLoader(test_ds, batch_size=128)\n```\n:::\n\n\n# Transfer learning from ImageNet to MoNuSAC\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Use the pre-trained InceptionV3 model from `torchvision`\n\n::: {#e9c0ec6b .cell execution_count=10}\n``` {.python .cell-code}\nimport torch\n\ndl_model = torchvision.models.inception_v3(\n    inception_weights,\n    progress=True\n)\n\ndl_model.eval()\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Replace the classifier for a MLP with the output number of classes of the MoNuSAS dataset\n\n::: {#cec30ed3 .cell execution_count=11}\n``` {.python .cell-code}\nimport torch.nn as nn\n\ndl_model.fc = nn.Sequential(\n    nn.Linear(in_features=2048, out_features=1024, bias=True),\n    nn.ReLU(),\n    nn.Linear(in_features=1024, out_features=4, bias=True)\n)\n```\n:::\n\n\n- [ ] Freeze all layers but the MLP that serves as classifier.\n\n::: {#81c0cedb .cell execution_count=12}\n``` {.python .cell-code}\nfor param in dl_model.parameters():\n    param.requires_grad = False\n\ndl_model.eval()\n\nfor param in dl_model.fc.parameters():\n    param.requires_grad = True\n\ndl_model.fc.train()\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Define the optimization method and loss function.\n\n::: {#1d4627c0 .cell execution_count=13}\n``` {.python .cell-code}\nimport torch.optim as optim\n\noptimizer = optim.Adam(dl_model.fc.parameters(), lr=0.001, weight_decay=0.001)\n\nloss_fun = nn.CrossEntropyLoss()\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Implement the training step\n\n::: {#e6541894 .cell overflow-y='true' execution_count=14}\n``` {.python .cell-code}\nif torch.cuda.is_available():\n    dl_model.cuda()\n\navg_train_loss = 0\ntotal_train_samples = 0\n\ndl_model.fc.train()\nfor x, y in train_dl:\n    optimizer.zero_grad()\n\n    if torch.cuda.is_available():\n        x = x.cuda()\n\n    y_hat = dl_model(x).cpu()\n\n    loss = loss_fun(y_hat, y)\n\n    loss.backward()\n\n    optimizer.step()\n\n    avg_train_loss += loss.item() * len(y)\n    total_train_samples += len(y)\n\navg_train_loss /= total_train_samples\nprint(f\"Train loss={avg_train_loss}\")\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Implement the validation step\n\n::: {#e2f3f905 .cell overflow-y='true' execution_count=15}\n``` {.python .cell-code}\navg_val_loss = 0\ntotal_val_samples = 0\n\ndl_model.fc.eval()\nwith torch.no_grad():\n    for x, y in val_dl:\n        if torch.cuda.is_available():\n            x = x.cuda()\n\n        y_hat = dl_model(x).cpu()\n\n        loss = loss_fun(y_hat, y)\n\n        avg_val_loss += loss.item() * len(y)\n        total_val_samples += len(y)\n\navg_val_loss /= total_val_samples\nprint(f\"Validation loss={avg_val_loss}\")\n```\n:::\n\n\n# Fine tune the model for tissue classification with the MoNuSAC dataset\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Put those two steps together inside an epoch loop and measure the accuracy of the model\n\n::: {#97803b12 .cell overflow-y='true' execution_count=16}\n``` {.python .cell-code}\nfrom torchmetrics.classification import Accuracy\n\nif torch.cuda.is_available():\n    dl_model.cuda()\n\ntrain_acc_metric = Accuracy(task=\"multiclass\", num_classes=4)\nval_acc_metric = Accuracy(task=\"multiclass\", num_classes=4)\n\nnum_epochs = 20\nfor e in range(num_epochs):\n    avg_train_loss = 0\n    total_train_samples = 0\n\n    dl_model.fc.train()\n    for x, y in train_dl:\n        optimizer.zero_grad()\n\n        if torch.cuda.is_available():\n            x = x.cuda()\n\n        y_hat = dl_model(x).cpu()\n\n        loss = loss_fun(y_hat, y)\n\n        loss.backward()\n\n        optimizer.step()\n\n        avg_train_loss += loss.item() * len(y)\n        total_train_samples += len(y)\n\n        train_acc_metric(y_hat.softmax(dim=1), y)\n\n    avg_train_loss /= total_train_samples\n    train_acc = train_acc_metric.compute()\n\n    avg_val_loss = 0\n    total_val_samples = 0\n\n    dl_model.fc.eval()\n    with torch.no_grad():\n        for x, y in val_dl:\n            if torch.cuda.is_available():\n                x = x.cuda()\n\n            y_hat = dl_model(x).cpu()\n\n            loss = loss_fun(y_hat, y)\n\n            avg_val_loss += loss.item() * len(y)\n            total_val_samples += len(y)\n\n            val_acc_metric(y_hat.softmax(dim=1), y)\n\n    avg_val_loss /= total_val_samples\n    val_acc = val_acc_metric.compute()\n\n    print(f\"[{(e + 1) / num_epochs: 2.2%}] Train loss={avg_train_loss: 2.4} (Acc={train_acc: 2.2%}), Validation loss={avg_val_loss: 2.4} (Acc={val_acc: 2.2%})\")\n\n    train_acc_metric.reset()\n    val_acc_metric.reset()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 5.00%] Train loss= 1.458 (Acc= 31.55%), Validation loss= 1.471 (Acc= 17.07%)\n[ 10.00%] Train loss= 1.291 (Acc= 38.69%), Validation loss= 1.313 (Acc= 24.39%)\n[ 15.00%] Train loss= 1.162 (Acc= 50.00%), Validation loss= 1.329 (Acc= 26.83%)\n[ 20.00%] Train loss= 1.028 (Acc= 62.50%), Validation loss= 1.305 (Acc= 39.02%)\n[ 25.00%] Train loss= 0.8927 (Acc= 76.79%), Validation loss= 1.29 (Acc= 39.02%)\n[ 30.00%] Train loss= 0.8068 (Acc= 70.24%), Validation loss= 1.255 (Acc= 51.22%)\n[ 35.00%] Train loss= 0.7616 (Acc= 72.02%), Validation loss= 1.418 (Acc= 36.59%)\n[ 40.00%] Train loss= 0.6216 (Acc= 82.14%), Validation loss= 1.256 (Acc= 48.78%)\n[ 45.00%] Train loss= 0.5317 (Acc= 87.50%), Validation loss= 1.459 (Acc= 39.02%)\n[ 50.00%] Train loss= 0.4719 (Acc= 88.10%), Validation loss= 1.322 (Acc= 48.78%)\n[ 55.00%] Train loss= 0.4233 (Acc= 89.88%), Validation loss= 1.484 (Acc= 34.15%)\n[ 60.00%] Train loss= 0.4569 (Acc= 86.31%), Validation loss= 1.779 (Acc= 46.34%)\n[ 65.00%] Train loss= 0.3873 (Acc= 89.29%), Validation loss= 1.474 (Acc= 39.02%)\n[ 70.00%] Train loss= 0.3403 (Acc= 92.26%), Validation loss= 1.646 (Acc= 51.22%)\n[ 75.00%] Train loss= 0.2852 (Acc= 94.64%), Validation loss= 1.535 (Acc= 39.02%)\n[ 80.00%] Train loss= 0.2652 (Acc= 94.05%), Validation loss= 1.518 (Acc= 53.66%)\n[ 85.00%] Train loss= 0.2109 (Acc= 96.43%), Validation loss= 1.48 (Acc= 39.02%)\n[ 90.00%] Train loss= 0.1441 (Acc= 98.81%), Validation loss= 1.476 (Acc= 43.90%)\n[ 95.00%] Train loss= 0.1203 (Acc= 99.40%), Validation loss= 1.56 (Acc= 51.22%)\n[ 100.00%] Train loss= 0.1117 (Acc= 99.40%), Validation loss= 1.479 (Acc= 48.78%)\n```\n:::\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Compute the performance of the model on the test set\n\n::: {#4f41dd86 .cell execution_count=17}\n``` {.python .cell-code}\navg_test_loss = 0\ntotal_test_samples = 0\n\ntest_acc_metric = Accuracy(task=\"multiclass\", num_classes=4)\n\ndl_model.fc.eval()\nwith torch.no_grad():\n    for x, y in test_dl:\n        if torch.cuda.is_available():\n            x = x.cuda()\n\n        y_hat = dl_model(x).cpu()\n\n        loss = loss_fun(y_hat, y)\n\n        avg_test_loss += loss.item() * len(y)\n        total_test_samples += len(y)\n\n        test_acc_metric(y_hat.softmax(dim=1), y)\n\navg_test_loss /= total_test_samples\ntest_acc = test_acc_metric.compute()\n\nprint(f\"Test loss={avg_test_loss: 2.4} (Acc={test_acc: 2.2%})\")\n\ntest_acc_metric.reset()\n```\n:::\n\n\n---\n\n## Tissue classification with the MoNuSAC dataset\n\n- [ ] Save the current state of the model\n\n::: {#ce1290c9 .cell execution_count=18}\n``` {.python .cell-code}\ncheckpoint = dl_model.state_dict()\ntorch.save(checkpoint, \"monusac_checkpoint.pt\")\n```\n:::\n\n\n# Explore the MoNuSAC dataset in the embedded feature space\n\n---\n\n## Explore the MoNuSAC dataset in the embedded feature space\n\n- [ ] Extract the *embedded* features from the train set.\n\n::: {#f6997d56 .cell execution_count=19}\n``` {.python .cell-code}\nimport numpy as np\n\nif torch.cuda.is_available():\n    dl_model.cuda()\n\ntrain_features = []\ntrain_labels = []\n\ndl_model.fc[1] = nn.Identity()\n\ndl_model.eval()\nwith torch.no_grad():\n    for x, y in train_dl:\n        if torch.cuda.is_available():\n            x = x.cuda()\n\n        fx = dl_model(x).cpu().detach().numpy()\n\n        train_features.append(fx)\n        train_labels.append(y.numpy())\n\ntrain_features = np.concatenate(train_features, 0)\ntrain_labels = np.concatenate(train_labels, 0)\n```\n:::\n\n\n---\n\n## Explore the MoNuSAC dataset in the embedded feature space\n\n- [ ] Project the features into a two-dimensional UMap.\n\n::: {#212937f8 .cell execution_count=20}\n``` {.python .cell-code}\nimport umap\n\nreducer = umap.UMAP()\n\nembedding = reducer.fit_transform(train_features)\n\nembedding.shape\n```\n:::\n\n\n---\n\n## Explore the MoNuSAC dataset in the embedded feature space\n\n- [ ] Show the embedded space.\n\n::: {#000e05f9 .cell execution_count=21}\n``` {.python .cell-code code-fold=\"true\"}\nimport matplotlib.pyplot as plt\n\nfor c in range(4):\n    plt.scatter(embedding[train_labels == c, 0], embedding[train_labels == c, 1], label=tissue_classes[c])\n\nplt.legend()\nplt.gca().set_aspect('equal', 'datalim')\nplt.title('UMAP projection of InceptionV3 features of the MoNuSAC dataset', fontsize=24)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\nText(0.5, 1.0, 'UMAP projection of InceptionV3 features of the MoNuSAC dataset')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DL_image_analysis_2_2_files/figure-revealjs/cell-21-output-2.png){width=1067 height=444}\n:::\n:::\n\n\n---\n\n## Explore the MoNuSAC dataset in the embedded feature space\n\n- [ ] Extract the *embedded* features from the validation and test sets.\n\n::: {#869ce734 .cell overflow-y='true' execution_count=22}\n``` {.python .cell-code}\nval_features = []\nval_labels = []\n\ntest_features = []\ntest_labels = []\n\nwith torch.no_grad():\n    for x, y in val_dl:\n        if torch.cuda.is_available():\n            x = x.cuda()\n\n        fx = dl_model(x).cpu().detach().numpy()\n\n        val_features.append(fx)\n        val_labels.append(y.numpy())\n\nval_features = np.concatenate(val_features, 0)\nval_labels = np.concatenate(val_labels, 0)\n\nwith torch.no_grad():\n    for x, y in test_dl:\n        if torch.cuda.is_available():\n            x = x.cuda()\n\n        fx = dl_model(x).cpu().detach().numpy()\n\n        test_features.append(fx)\n        test_labels.append(y.numpy())\n\ntest_features = np.concatenate(test_features, 0)\ntest_labels = np.concatenate(test_labels, 0)\n```\n:::\n\n\n---\n\n## Explore the MoNuSAC dataset in the embedded feature space {.scrollable}\n\n- [ ] Project the features of the test and validation sets into a two-dimensional UMap.\n\n::: {#e9a25643 .cell execution_count=23}\n``` {.python .cell-code}\nembedding_val = reducer.transform(val_features)\nembedding_test = reducer.transform(test_features)\n```\n:::\n\n\n- [ ] Show the embedded space.\n\n::: {#9b46442d .cell execution_count=24}\n``` {.python .cell-code code-fold=\"true\"}\nfor c in range(4):\n    plt.scatter(embedding[train_labels == c, 0], embedding[train_labels == c, 1], label=tissue_classes[c] + \" (train)\", marker=\"o\")\n\nfor c in range(4):\n    plt.scatter(embedding_val[val_labels == c, 0], embedding_val[val_labels == c, 1], label=tissue_classes[c] + \" (validation)\", marker=\"v\")\n\nfor c in range(4):\n    plt.scatter(embedding_test[test_labels == c, 0], embedding_test[test_labels == c, 1], label=tissue_classes[c] + \" (test)\", marker=\"s\")\n\nplt.legend()\nplt.gca().set_aspect('equal', 'datalim')\nplt.title('UMAP projection of InceptionV3 features of the MoNuSAC dataset', fontsize=24)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\nText(0.5, 1.0, 'UMAP projection of InceptionV3 features of the MoNuSAC dataset')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DL_image_analysis_2_2_files/figure-revealjs/cell-24-output-2.png){width=1067 height=444}\n:::\n:::\n\n\n",
    "supporting": [
      "DL_image_analysis_2_2_files"
    ],
    "filters": [],
    "includes": {}
  }
}