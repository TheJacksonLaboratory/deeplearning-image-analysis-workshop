---
title: Advanced Machine Learning with Python (Session 2 - Part 1)
author: Fernando Cervantes (fernando.cervantes@jax.org)
format: 
  revealjs:
    code-fold: false
    progress: true
    controls: true
    output-file: "Adv_ML_Python_presentation_2_1"
    fontsize: 20pt
    include-in-header: 
      text: |
        <link href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.3/css/bootstrap.min.css" rel ="stylesheet" integrity="sha512-jnSuA4Ss2PkkikSOLtYs8BlYIeeIK1h99ty4YfvRPAlzr377vr3CXDb7sb7eEEBYjDtcYj+AjBH3FLv5uSJuXg==" crossorigin="anonymous">

execute:
  error: true
  echo: true
  cache: true
  freeze: true
  keep-ipynb: true

jupyter: python3
---

## Workshop outcomes

* Understand the process of training ML models.
*	Load pre-trained ML models and fine-tune them with new data.
*	Evaluate the performance of ML models.
*	Adapt ML models for different tasks from pre-trained models.


## Materials

[Open notebook in Colab](https://colab.research.google.com/gist/fercer/16149e05e7b2046f9d78940007fa4c2a/advanced_machine_learning_with_python_session_2_1.ipynb){.btn .btn-outline-primary .btn role="button" target=‚Äù_blank‚Äù} [View solutions](https://colab.research.google.com/gist/fercer/a357c3341ea726f7b4328d47155752d1/advanced_machine_learning_with_python_session_2_1-solved.ipynb){.btn .btn-outline-primary .btn role="button" target=‚Äù_blank‚Äù}


# 0. Setup environment

## Select runtime and connect


On the top right corner of the page, click the drop-down arrow to the right of the `Connect` button and select `Change runtime type`.

![](../imgs/connect_runtime.png){width=50%}

---

Make sure `Python 3` runtime is selected. For this part of the workshop `CPU` acceleration is enough.

![](../imgs/select_runtime.png){width=50%}

---

Now we can connect to the runtime by clicking `Connect`. This will create a **V**irtual **M**achine (**VM**) with compute resources we can use for a limited amount of time.

![](../imgs/connect.png){height=25%}

:::{.callout-caution}
In free Colab accounts these resources are not guaranteed and can be taken away without notice (preemptible machines).

Data stored in this runtime will be lost if not moved into other storage when the runtime is deleted.
:::

# Load pre-trained models

---

## Load pre-trained models

* Lets use one from the PyTorch's `torchvision` module for computer vision

* Try first with the InceptionV3 model. 
![InceptionV3](../imgs/Inception.png)

---

## Exercise: Use a pre-trained deep learning model to classify images {.scrollable}
 
- [ ] Import the pre-trained weights of the Inception V3 model from models.inception_v3

``` {python}
import torch
from torchvision import models

inception_weights = models.inception.Inception_V3_Weights.IMAGENET1K_V1

inception_weights.meta
```

- [ ] Store the categories in a variable to use them later

``` {python}
categories = inception_weights.meta["categories"]
```

::: {.callout-tip}
More info about Inception V3 implementation in `torchvision` [here](https://pytorch.org/vision/main/models/generated/models.inception_v3.html)
:::

---

## Exercise: Use a pre-trained deep learning model to classify images {.scrollable}

- [ ] Load the Inception V3 model using the pre-trained weights `inception_weights`

``` {python}
dl_model = models.inception_v3(inception_weights, progress=True)

dl_model.eval()
```

---

## Exercise: Use a pre-trained deep learning model to classify images {.scrollable}

- [ ] Load a sample image to predict its category

``` {python}
import skimage
import matplotlib.pyplot as plt

sample_im = skimage.data.rocket()
sample_im.shape
```

---

## Exercise: Use a pre-trained deep learning model to classify images {.scrollable}

- [ ] Visualize the sample image

``` {python}
plt.imshow(sample_im)
plt.show()
```

---

## Exercise: Use a pre-trained deep learning model to classify images

- [ ] Inspect what transforms are required by the pre-trained Inception model to work properly

``` {python}
inception_weights.transforms
```

::: {.callout-important}
`functools.partial` is a function to define functions with static arguments. So üëÜ returns a function when it is called!
:::

::: {.callout-note}
The transforms used by the Inception V3 are

  1. resize the image to 342x342 pixels,

  2. crop the center 299x299 pixels window, and

  3. normalize the values of the RGB channels.
:::

---

## Exercise: Use a pre-trained deep learning model to classify images

- [ ] Define a preprocessing pipeline using the inception_weights.transforms() method. Add also a transformation from `numpy` arrays into torch tensors.

``` {python}
from torchvision.transforms.v2 import Compose, ToTensor

pipeline = Compose([
  ToTensor(),
  inception_weights.transforms()
])

pipeline
```

---

## Exercise: Use a pre-trained deep learning model to classify images

- [ ] Pre-process the sample image using our pipeline

``` {python}
sample_x = pipeline(sample_im)
type(sample_x), sample_x.shape, sample_x.min(), sample_x.max()
```

---

## Exercise: Use a pre-trained deep learning model to classify images

- [ ] Use the pre-trained model to predict the class of our sample image

::: {.callout-caution}
Apply the model on sample_x[None, ...], so it is treated as a one-sample batch
:::

``` {python}
sample_y = dl_model(sample_x[None, ...])

sample_y.shape
```

---

## Exercise: Use a pre-trained deep learning model to classify images {.scrollable}

::: {.callout-note}
The model's output are the log-probabilities of `sample_x` belonging to each of the 1000 classes.
:::

- [ ] Show the categories with the highest *log-*probabilities.

``` {python}
sample_y.argsort(dim=1)
```

---

## Exercise: Use a pre-trained deep learning model to classify images {.scrollable}

- [ ] Use the list of categories to translate the predicted class index into its category.

``` {python}

sorted_predicted_classes = sample_y.argsort(dim=1, descending=True)[0, :10]
sorted_probs = torch.softmax(sample_y, dim=1)[0, sorted_predicted_classes]

for idx, prob in zip(sorted_predicted_classes, sorted_probs):
    print(categories[idx], "%3.2f %%" % (prob * 100))
```

# Try with other sample images (only works with RGB!)

---

## Try with other sample images {.scrollable}

::: {.callout-caution}
Only works with RGB images
:::

- [ ] Use the pre-trained model to classify images from the internet (try some from the [Kodak Lossless True Color Image Suite](https://r0k.us/graphics/kodak/)).

``` {python}
sample_im = skimage.io.imread("https://r0k.us/graphics/kodak/kodak/kodim21.png")
sample_x = pipeline(sample_im)
sample_y = dl_model(sample_x[None, ...])

plt.imshow(sample_im)
plt.title(categories[sample_y.argmax(dim=1)])
plt.show()

sorted_predicted_classes = sample_y.argsort(dim=1, descending=True)[0, :10]
sorted_probs = torch.softmax(sample_y, dim=1)[0, sorted_predicted_classes]

for idx, prob in zip(sorted_predicted_classes, sorted_probs):
    print(categories[idx], "%3.2f %%" % (prob * 100))
```

- [ ] Try with an image from a category that is not in the labels set of the model (like one with [hanging caps](https://r0k.us/graphics/kodak/kodak/kodim03.png))

# Using Deep Learning models as feature extractors

## Exercise: Modify the classifier layer `dl_model.fc` to return the features map from the input image instead of the category

::: {.callout-tip}
The classifier layer is commonly implemented as a MultiLayer Perceptron (Fully connected) at the end of the models.
The specific name of that layer can vary between implementations.
:::

- [ ] Load the pre-trained Inception V3 model again to use it as feature extractor.

``` {python}
dl_extractor = models.inception_v3(inception_weights, progress=True)
dl_extractor.eval()

dl_extractor.fc
```

---

## Exercise: Modify the classifier layer `dl_model.fc` to return the features map from the input image instead of the category

- [ ] Replace the `.fc` layer with a `torch.nn.Identity` module.

``` {python}
dl_extractor.fc = torch.nn.Identity()
```

- [ ] Use the model for feature extraction in the same way it is used for image classification.

``` {python}
sample_fx = dl_extractor(sample_x[None, ...])

sample_fx.shape
```
