---
title: Advanced Machine Learning with Python (Session 2 - Part 2)
author: Fernando Cervantes (fernando.cervantes@jax.org)
format: 
  revealjs:
    code-fold: false
    progress: true
    controls: true
    output-file: "Adv_ML_Python_presentation_2_2"
    fontsize: 20pt

execute:
  error: false
  echo: true
  cache: true
  freeze: true
  keep-ipynb: true

jupyter: adv-ml
---

``` {.python}

```

# Tissue classification with the MoNuSAC dataset

## Tissue classification with the MoNuSAC dataset

* R. Verma, et al. "MoNuSAC2020: A Multi-organ Nuclei Segmentation and Classification Challenge." IEEE Transactions on Medical Imaging (2021)

![](../imgs/Tissue_classification.png)


## Data preparation

- [ ] Download the MoNuSAC dataset from https://monusac-2020.grand-challenge.org/Data/

``` {python}
#| echo: false
#| output: false
tissue_classes = [
    'Lung',
    'Kidney',
    'Breast',
    'Prostate',
]

tissue_per_train_files = {
    "TCGA-55-1594": 0,
    "TCGA-69-7760": 0,
    "TCGA-69-A59K": 0,
    "TCGA-73-4668": 0,
    "TCGA-78-7220": 0,
    "TCGA-86-7713": 0,
    "TCGA-86-8672": 0,
    "TCGA-L4-A4E5": 0,
    "TCGA-MP-A4SY": 0,
    "TCGA-MP-A4T7": 0,
    "TCGA-5P-A9K0": 1,
    "TCGA-B9-A44B": 1,
    "TCGA-B9-A8YI": 1,
    "TCGA-DW-7841": 1,
    "TCGA-EV-5903": 1,
    "TCGA-F9-A97G": 1,
    "TCGA-G7-A8LD": 1,
    "TCGA-MH-A560": 1,
    "TCGA-P4-AAVK": 1,
    "TCGA-SX-A7SR": 1,
    "TCGA-UZ-A9PO": 1,
    "TCGA-UZ-A9PU": 1,
    "TCGA-A2-A0CV": 2,
    "TCGA-A2-A0ES": 2,
    "TCGA-B6-A0WZ": 2,
    "TCGA-BH-A18T": 2,
    "TCGA-D8-A1X5": 2,
    "TCGA-E2-A154": 2,
    "TCGA-E9-A22B": 2,
    "TCGA-E9-A22G": 2,
    "TCGA-EW-A6SD": 2,
    "TCGA-S3-AA11": 2,
    "TCGA-EJ-5495": 3,
    "TCGA-EJ-5505": 3,
    "TCGA-EJ-5517": 3,
    "TCGA-G9-6342": 3,
    "TCGA-G9-6499": 3,
    "TCGA-J4-A67Q": 3,
    "TCGA-J4-A67T": 3,
    "TCGA-KK-A59X": 3,
    "TCGA-KK-A6E0": 3,
    "TCGA-KK-A7AW": 3,
    "TCGA-V1-A8WL": 3,
    "TCGA-V1-A9O9": 3,
    "TCGA-X4-A8KQ": 3,
    "TCGA-YL-A9WY": 3,
}

tissue_per_test_files = {
    "TCGA-49-6743": 0,
    "TCGA-50-6591": 0,
    "TCGA-55-7570": 0,
    "TCGA-55-7573": 0,
    "TCGA-73-4662": 0,
    "TCGA-78-7152": 0,
    "TCGA-MP-A4T7": 0,
    "TCGA-2Z-A9JG": 1,
    "TCGA-2Z-A9JN": 1,
    "TCGA-DW-7838": 1,
    "TCGA-DW-7963": 1,
    "TCGA-F9-A8NY": 1,
    "TCGA-IZ-A6M9": 1,
    "TCGA-MH-A55W": 1,
    "TCGA-A2-A04X": 2,
    "TCGA-A2-A0ES": 2,
    "TCGA-D8-A3Z6": 2,
    "TCGA-E2-A108": 2,
    "TCGA-EW-A6SB": 2,
    "TCGA-G9-6356": 3,
    "TCGA-G9-6367": 3,
    "TCGA-VP-A87E": 3,
    "TCGA-VP-A87H": 3,
    "TCGA-X4-A8KS": 3,
    "TCGA-YL-A9WL": 3,
}
```
``` {python}
#| output: false
#| echo: false
data_dir = "/flashscratch/cervaf/data"

from glob import glob

train_images_fns = glob(data_dir + "/monusac_train/*/*.svs")
test_images_fns = glob(data_dir + "/monusac_test/*/*.svs")

train_labels = [
    tissue_per_train_files[fn.split("/")[-2][:12]]
    for fn in train_images_fns
]

test_labels = [
    tissue_per_test_files[fn.split("/")[-2][:12]]
    for fn in test_images_fns
]
```

::: {.callout-note}
More information about the type of tissue of each image can be found [here](https://drive.google.com/file/d/1kdOl3s6uQBRv0nToSIf1dPuceZunzL4N/view).
:::

---

## Tissue classification with the MoNuSAC dataset {.scrollable}

- [ ] Explore the dataset

``` {python}
from skimage.io import imread
import matplotlib.pyplot as plt

img = imread(train_images_fns[0])
plt.imshow(img)
plt.title(tissue_classes[train_labels[0]])
plt.show()

img = imread(test_images_fns[0])
plt.imshow(img)
plt.title(tissue_classes[test_labels[0]])
plt.show()
```

## Tissue classification with the MoNuSAC dataset

- [ ] Define the pre-processing pipeline using the transforms from the pre-trained InceptionV3 model

``` {python}
#| output: false
import torchvision
from torchvision.transforms.v2 import Compose, ToTensor

inception_weights = torchvision.models.inception.Inception_V3_Weights.IMAGENET1K_V1

pipeline = Compose([
  ToTensor(),
  inception_weights.transforms()
])

pipeline
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Create a dataset class to load the images from disk

``` {python}
#| output: false
from torch.utils.data import Dataset

class CustomImageDataset(Dataset):
    def __init__(self, image_filenames, image_labels, transform):
        self.image_filenames = image_filenames
        self.image_labels = image_labels
        self.transform = transform

    def __len__(self):
        return len(self.image_labels)

    def __getitem__(self, idx):
        image = imread(self.image_filenames[idx])
        image = self.transform(image)

        label = self.image_labels[idx]

        return image, label
```

- [ ] Create the training and test sets using the `CustomImageDataset` class.

``` {python}
#| output: false
train_ds = CustomImageDataset(train_images_fns, train_labels, pipeline)
test_ds = CustomImageDataset(test_images_fns, test_labels, pipeline)
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Split the training set into train and validation subsets

``` {python}
#| output: false
from torch.utils.data import random_split

train_ds, val_ds = random_split(train_ds, [0.8, 0.2])

print(f"Training images={len(train_ds)}")
print(f"Validation images={len(val_ds)}")
print(f"Test images={len(test_ds)}")
```

- [ ] Use a `DataLoader` to serve image batches from the datasets.

``` {python}
#| output: false
from torch.utils.data import DataLoader

train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
val_dl = DataLoader(val_ds, batch_size=128)
test_dl = DataLoader(test_ds, batch_size=128)
```

# Transfer learning from ImageNet to MoNuSAC

---

## Tissue classification with the MoNuSAC dataset

- [ ] Use the pre-trained InceptionV3 model from `torchvision`

``` {python}
#| output: false
import torch

dl_model = torchvision.models.inception_v3(
    inception_weights,
    progress=True
)

dl_model.eval()
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Replace the classifier for a MLP with the output number of classes of the MoNuSAS dataset

``` {python}
#| output: false
import torch.nn as nn

dl_model.fc = nn.Sequential(
    nn.Linear(in_features=2048, out_features=1024, bias=True),
    nn.ReLU(),
    nn.Linear(in_features=1024, out_features=4, bias=True)
)
```

- [ ] Freeze all layers but the MLP that serves as classifier.

``` {python}
#| output: false
for param in dl_model.parameters():
    param.requires_grad = False

dl_model.eval()

for param in dl_model.fc.parameters():
    param.requires_grad = True

dl_model.fc.train()
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Define the optimization method and loss function.

``` {python}
#| output: false
import torch.optim as optim

optimizer = optim.Adam(dl_model.fc.parameters(), lr=0.001, weight_decay=0.001)

loss_fun = nn.CrossEntropyLoss()
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Implement the training step

``` {python}
#| output: false
#| overflow-y: true
if torch.cuda.is_available():
    dl_model.cuda()

avg_train_loss = 0
total_train_samples = 0

dl_model.fc.train()
for x, y in train_dl:
    optimizer.zero_grad()

    if torch.cuda.is_available():
        x = x.cuda()

    y_hat = dl_model(x).cpu()

    loss = loss_fun(y_hat, y)

    loss.backward()

    optimizer.step()

    avg_train_loss += loss.item() * len(y)
    total_train_samples += len(y)

avg_train_loss /= total_train_samples
print(f"Train loss={avg_train_loss}")
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Implement the validation step

``` {python}
#| output: false
#| overflow-y: true
avg_val_loss = 0
total_val_samples = 0

dl_model.fc.eval()
with torch.no_grad():
    for x, y in val_dl:
        if torch.cuda.is_available():
            x = x.cuda()

        y_hat = dl_model(x).cpu()

        loss = loss_fun(y_hat, y)

        avg_val_loss += loss.item() * len(y)
        total_val_samples += len(y)

avg_val_loss /= total_val_samples
print(f"Validation loss={avg_val_loss}")
```

# Fine tune the model for tissue classification with the MoNuSAC dataset

---

## Tissue classification with the MoNuSAC dataset

- [ ] Put those two steps together inside an epoch loop and measure the accuracy of the model

``` {python}
#| overflow-y: true
from torchmetrics.classification import Accuracy

if torch.cuda.is_available():
    dl_model.cuda()

train_acc_metric = Accuracy(task="multiclass", num_classes=4)
val_acc_metric = Accuracy(task="multiclass", num_classes=4)

num_epochs = 20
for e in range(num_epochs):
    avg_train_loss = 0
    total_train_samples = 0

    dl_model.fc.train()
    for x, y in train_dl:
        optimizer.zero_grad()

        if torch.cuda.is_available():
            x = x.cuda()

        y_hat = dl_model(x).cpu()

        loss = loss_fun(y_hat, y)

        loss.backward()

        optimizer.step()

        avg_train_loss += loss.item() * len(y)
        total_train_samples += len(y)

        train_acc_metric(y_hat.softmax(dim=1), y)

    avg_train_loss /= total_train_samples
    train_acc = train_acc_metric.compute()

    avg_val_loss = 0
    total_val_samples = 0

    dl_model.fc.eval()
    with torch.no_grad():
        for x, y in val_dl:
            if torch.cuda.is_available():
                x = x.cuda()

            y_hat = dl_model(x).cpu()

            loss = loss_fun(y_hat, y)

            avg_val_loss += loss.item() * len(y)
            total_val_samples += len(y)

            val_acc_metric(y_hat.softmax(dim=1), y)

    avg_val_loss /= total_val_samples
    val_acc = val_acc_metric.compute()

    print(f"[{(e + 1) / num_epochs: 2.2%}] Train loss={avg_train_loss: 2.4} (Acc={train_acc: 2.2%}), Validation loss={avg_val_loss: 2.4} (Acc={val_acc: 2.2%})")

    train_acc_metric.reset()
    val_acc_metric.reset()
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Compute the performance of the model on the test set

``` {python}
#| output: false
avg_test_loss = 0
total_test_samples = 0

test_acc_metric = Accuracy(task="multiclass", num_classes=4)

dl_model.fc.eval()
with torch.no_grad():
    for x, y in test_dl:
        if torch.cuda.is_available():
            x = x.cuda()

        y_hat = dl_model(x).cpu()

        loss = loss_fun(y_hat, y)

        avg_test_loss += loss.item() * len(y)
        total_test_samples += len(y)

        test_acc_metric(y_hat.softmax(dim=1), y)

avg_test_loss /= total_test_samples
test_acc = test_acc_metric.compute()

print(f"Test loss={avg_test_loss: 2.4} (Acc={test_acc: 2.2%})")

test_acc_metric.reset()
```

---

## Tissue classification with the MoNuSAC dataset

- [ ] Save the current state of the model

``` {python}
#| output: false
checkpoint = dl_model.state_dict()
torch.save(checkpoint, "monusac_checkpoint.pt")
```

# Explore the MoNuSAC dataset in the embedded feature space

---

## Explore the MoNuSAC dataset in the embedded feature space

- [ ] Extract the *embedded* features from the train set.

``` {python}
#| output: false
import numpy as np

if torch.cuda.is_available():
    dl_model.cuda()

train_features = []
train_labels = []

dl_model.fc[1] = nn.Identity()

dl_model.eval()
with torch.no_grad():
    for x, y in train_dl:
        if torch.cuda.is_available():
            x = x.cuda()

        fx = dl_model(x).cpu().detach().numpy()

        train_features.append(fx)
        train_labels.append(y.numpy())

train_features = np.concatenate(train_features, 0)
train_labels = np.concatenate(train_labels, 0)
```

---

## Explore the MoNuSAC dataset in the embedded feature space

- [ ] Project the features into a two-dimensional UMap.

``` {python}
#| output: false
import umap

reducer = umap.UMAP()

embedding = reducer.fit_transform(train_features)

embedding.shape
```

---

## Explore the MoNuSAC dataset in the embedded feature space

- [ ] Show the embedded space.

``` {python}
#| code-fold: true
import matplotlib.pyplot as plt

for c in range(4):
    plt.scatter(embedding[train_labels == c, 0], embedding[train_labels == c, 1], label=tissue_classes[c])

plt.legend()
plt.gca().set_aspect('equal', 'datalim')
plt.title('UMAP projection of InceptionV3 features of the MoNuSAC dataset', fontsize=24)
```

---

## Explore the MoNuSAC dataset in the embedded feature space

- [ ] Extract the *embedded* features from the validation and test sets.

``` {python}
#| output: false
#| overflow-y: true
val_features = []
val_labels = []

test_features = []
test_labels = []

with torch.no_grad():
    for x, y in val_dl:
        if torch.cuda.is_available():
            x = x.cuda()

        fx = dl_model(x).cpu().detach().numpy()

        val_features.append(fx)
        val_labels.append(y.numpy())

val_features = np.concatenate(val_features, 0)
val_labels = np.concatenate(val_labels, 0)

with torch.no_grad():
    for x, y in test_dl:
        if torch.cuda.is_available():
            x = x.cuda()

        fx = dl_model(x).cpu().detach().numpy()

        test_features.append(fx)
        test_labels.append(y.numpy())

test_features = np.concatenate(test_features, 0)
test_labels = np.concatenate(test_labels, 0)
```

---

## Explore the MoNuSAC dataset in the embedded feature space {.scrollable}

- [ ] Project the features of the test and validation sets into a two-dimensional UMap.

``` {python}
#| output: false
embedding_val = reducer.transform(val_features)
embedding_test = reducer.transform(test_features)
```

- [ ] Show the embedded space.

``` {python}
#| code-fold: true
for c in range(4):
    plt.scatter(embedding[train_labels == c, 0], embedding[train_labels == c, 1], label=tissue_classes[c] + " (train)", marker="o")

for c in range(4):
    plt.scatter(embedding_val[val_labels == c, 0], embedding_val[val_labels == c, 1], label=tissue_classes[c] + " (validation)", marker="v")

for c in range(4):
    plt.scatter(embedding_test[test_labels == c, 0], embedding_test[test_labels == c, 1], label=tissue_classes[c] + " (test)", marker="s")

plt.legend()
plt.gca().set_aspect('equal', 'datalim')
plt.title('UMAP projection of InceptionV3 features of the MoNuSAC dataset', fontsize=24)
```
